{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1e6cc80",
   "metadata": {},
   "source": [
    "# **Week 5: Feature Selection and Regularization on the Ames Housing Dataset**\n",
    "\n",
    "In this homework, we will experiment with two feature selection methods and one regularization technique for linear regression:\n",
    "- **Forward Selection**\n",
    "- **Backward Selection**\n",
    "- **Ridge Regression**\n",
    "\n",
    "We will apply these techniques to the preprocessed Ames Housing dataset from last week, evaluate which method achieves the best cross-validation (CV) score, and provide a final test score for the best model. \n",
    "\n",
    "There are 4 problems with 8 graded answers worth 6 points each, and you get 2 points free. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df84b742",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: kagglehub in /usr/local/python/3.12.1/lib/python3.12/site-packages (0.3.12)\n",
      "Requirement already satisfied: packaging in /home/codespace/.local/lib/python3.12/site-packages (from kagglehub) (24.2)\n",
      "Requirement already satisfied: pyyaml in /home/codespace/.local/lib/python3.12/site-packages (from kagglehub) (6.0.2)\n",
      "Requirement already satisfied: requests in /home/codespace/.local/lib/python3.12/site-packages (from kagglehub) (2.32.3)\n",
      "Requirement already satisfied: tqdm in /usr/local/python/3.12.1/lib/python3.12/site-packages (from kagglehub) (4.67.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/codespace/.local/lib/python3.12/site-packages (from requests->kagglehub) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/codespace/.local/lib/python3.12/site-packages (from requests->kagglehub) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/codespace/.local/lib/python3.12/site-packages (from requests->kagglehub) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/codespace/.local/lib/python3.12/site-packages (from requests->kagglehub) (2025.1.31)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f38fcab-bcb2-4b70-a304-6412d94a36df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/python/3.12.1/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Useful imports\n",
    "\n",
    "import os\n",
    "import kagglehub\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import io\n",
    "import zipfile\n",
    "\n",
    "from sklearn.model_selection   import train_test_split, cross_val_score,RepeatedKFold\n",
    "from sklearn.linear_model      import LinearRegression,Ridge,Lasso\n",
    "from sklearn.model_selection   import GridSearchCV\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.metrics           import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing     import StandardScaler \n",
    "\n",
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241380b6-01ad-4a90-91ee-d5c4f53b9218",
   "metadata": {},
   "source": [
    "## **Prelude: Download the Preprocessed Ames Housing Dataset**\n",
    "\n",
    "I have stored the dataset as a zipped directory containing the following four files from an 80%-20% split of the Ames dataset after preprocessing (as done in the last homework):\n",
    "\n",
    "- `X_train.csv`         \n",
    "- `y_train.csv`\n",
    "- `X_test.csv`          \n",
    "- `y_test.csv`\n",
    "\n",
    "**TODO:** Run the following cell to download and extract the dataset into the current working directory of this notebook.  \n",
    "Alternatively, you can manually download the zip file from the provided URL, extract it, and place the files in the same directory as your notebook.\n",
    "\n",
    "> ⚠️ **Important:**  \n",
    "> DO NOT use your own version of these datasets from the last homework. The autograder expects the exact split provided in my files for both training and testing sets. Using any other split will result in incorrect results during grading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd27c153-4225-4556-9515-cb6a917f4221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files downloaded and extracted successfully.\n",
      "Training and testing datasets loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "# Download the Ames Housing Dataset from Snyder's web site\n",
    "\n",
    "# URL to the zip file\n",
    "zip_url = \"https://www.cs.bu.edu/fac/snyder/cs505/Data/ames_housing.zip\"\n",
    "\n",
    "try:\n",
    "    response = requests.get(zip_url)\n",
    "    response.raise_for_status()  # Raise an error for bad status codes\n",
    "    with zipfile.ZipFile(io.BytesIO(response.content)) as zipf:\n",
    "        zipf.extractall(\"ames_data\")\n",
    "    print(\"Files downloaded and extracted successfully.\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error downloading the file: {e}\")\n",
    "\n",
    "# Load the datasets\n",
    "X_train = pd.read_csv(\"ames_data/X_train.csv\")\n",
    "X_test = pd.read_csv(\"ames_data/X_test.csv\")\n",
    "y_train = pd.read_csv(\"ames_data/y_train.csv\").squeeze(\"columns\")          # converted to a Series\n",
    "y_test = pd.read_csv(\"ames_data/y_test.csv\").squeeze(\"columns\")\n",
    "\n",
    "print(\"Training and testing datasets loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac6da55-0dc7-4509-b2d7-afd475af4060",
   "metadata": {},
   "source": [
    "## **Problem One: Forward Selection with the Ames Dataset**\n",
    "\n",
    "For our first experiment we will apply the forward feature selection algorithm to the dataset. Follow these steps, using the notebook from this week's video lesson as a resource as necessary. \n",
    "\n",
    "**If you have not looked at the video yet, please do it now before continuing.**\n",
    "\n",
    "**Steps to Follow:**\n",
    "1. **Observe** that we have provided the `forward_feature_selection` algorithm from the video notebook for you to use. \n",
    "\n",
    "2. **Copy** from the video notebook into the cell indicated below the code that runs forward feature selection and generates a plot (excluding the part that prints the test MSE--we'll do that at the end of this homework). Or write your own version!\n",
    "\n",
    "3. **Modify** this code to display the **Root Mean Squared Error (RMSE)** instead of MSE.  \n",
    "   - *Remember*: RMSE is the square root of MSE, which provides results in dollars rather than dollars squared, making the metric more interpretable.  \n",
    "   - Both the plot of RMSE vs. the number of selected features and the printout of the Best CV Score should use RMSE.\n",
    "\n",
    "4. **Run** the code on `X_train` and `y_train` (keeping all default settings) to:\n",
    "   - Generate the plot of **Root Mean Squared Error (RMSE)** vs. **Features Added**, and  \n",
    "   - Print the **Best Feature Set** found and the **Best CV RMSE Score**.\n",
    "\n",
    "**Hints:**\n",
    "- The feature names will be more legible if you increase the size of the plot and change the angle and size of the xticks, e.g.,\n",
    "\n",
    "        plt.xticks(range(1, len(selected_features_forward) + 1), selected_features_forward, rotation=60, ha='right', fontsize=6) \n",
    "\n",
    "- You may wish to change the scale of the y-axis to better see the behavior around the minimum point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a2c45d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_feature_selection(X, y, model, \n",
    "                                      scoring='neg_mean_squared_error', \n",
    "                                      cv=5, \n",
    "                                      tol=None,               # None = no delta cutoff\n",
    "                                                              # use 0.0 for \"no further improvements\"\n",
    "                                                              # and 1e-4 for \"point of diminishing returns\"                                      \n",
    "                                      max_features=None,      # None = use all features\n",
    "                                      n_jobs = -1,\n",
    "                                      verbose = True\n",
    "                                     ):\n",
    "    selected_features = []\n",
    "    remaining_features = list(X.columns)\n",
    "    best_scores = []\n",
    "    previous_score = float('inf')\n",
    "    \n",
    "    # Model to use for evaluation\n",
    "    model = LinearRegression()\n",
    "\n",
    "    # Track the best subset and its score\n",
    "    best_forward_features = None\n",
    "    best_score = float('inf')\n",
    "    \n",
    "    while remaining_features:\n",
    "        scores = {}\n",
    "        for feature in remaining_features:\n",
    "            current_features = selected_features + [feature]\n",
    "            # Compute the CV score\n",
    "            cv_score = -cross_val_score(model, X[current_features], y, \n",
    "                                        scoring=scoring, cv=cv,n_jobs=n_jobs,\n",
    "                                       ).mean()\n",
    "            scores[feature] = cv_score\n",
    "        # Select the feature that minimizes the CV score\n",
    "        best_feature = min(scores, key=scores.get)\n",
    "        current_score = scores[best_feature]\n",
    "\n",
    "        # Check if the improvement is significant\n",
    "        if verbose and tol is not None and previous_score - current_score < tol:\n",
    "            print(\"Stopping early due to minimal improvement.\")\n",
    "            break\n",
    "\n",
    "        # Add the best feature to the selected list\n",
    "        selected_features.append(best_feature)\n",
    "        best_scores.append(current_score)\n",
    "        remaining_features.remove(best_feature)\n",
    "        previous_score = current_score\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"Features: {selected_features}, CV Score (MSE): {current_score:.4f}\")\n",
    "        \n",
    "        # Update the best subset if the current score is the best so far\n",
    "        if current_score < best_score:\n",
    "            best_score = current_score\n",
    "            best_forward_features = selected_features.copy()\n",
    "        \n",
    "        # Check if max_features has been reached\n",
    "        if max_features is not None and len(selected_features) >= max_features:\n",
    "            break\n",
    "\n",
    "    return selected_features, best_scores, best_forward_features, best_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7227d05b-cc9a-4193-9a5e-703172193095",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Forward Feature Selection\n",
    "\n",
    "def forward_feature_selection(X, y, model, \n",
    "                              scoring='neg_mean_squared_error', \n",
    "                              cv = 5, \n",
    "                              tol=None,               # None = no delta cutoff\n",
    "                                                      # use 0.0 for \"no further improvements\"\n",
    "                                                      # and 1e-4 for \"point of diminishing returns\"                                      \n",
    "                              max_features=None,      # None = use all features\n",
    "                              n_jobs=-1,\n",
    "                              verbose=False\n",
    "                             ):\n",
    "    selected_features = []                            # List to store the order of features selected\n",
    "    remaining_features = list(X.columns)              # Features not yet selected\n",
    "    best_scores = []                                  # List to store the CV score after each feature addition\n",
    "    previous_score = float('inf')                     # Initialize previous score for improvement comparison\n",
    "\n",
    "    # Track the best subset of features and its corresponding score\n",
    "    \n",
    "    best_feature_set = None                           # Best combination of features found so far\n",
    "    best_score = float('inf')                         # Best CV score observed so far\n",
    "    \n",
    "    while remaining_features:\n",
    "        scores = {}                                   # Dictionary to hold CV scores for each candidate feature\n",
    "        for feature in remaining_features:\n",
    "            current_features = selected_features + [feature]\n",
    "            \n",
    "            # Compute the CV score for the current set of features (negated MSE, so lower is better)\n",
    "            cv_score = -cross_val_score(model, X[current_features], y, \n",
    "                                        scoring=scoring, cv=cv, n_jobs=n_jobs\n",
    "                                       ).mean()\n",
    "            scores[feature] = cv_score\n",
    "\n",
    "        # Select the feature that minimizes the CV score\n",
    "        best_feature = min(scores, key=scores.get)\n",
    "        current_score = scores[best_feature]\n",
    "            \n",
    "        # Check if the improvement is significant based on the tolerance (tol)\n",
    "        if tol is not None and previous_score - current_score < tol:\n",
    "            if verbose:\n",
    "                print(\"Stopping early due to minimal improvement.\")\n",
    "            break\n",
    "\n",
    "        # Add the best feature to the selected list and update score trackers\n",
    "        selected_features.append(best_feature)\n",
    "        best_scores.append(current_score)\n",
    "        remaining_features.remove(best_feature)\n",
    "        previous_score = current_score\n",
    "\n",
    "        if verbose:\n",
    "            print(f\"\\nFeatures: {selected_features[-3:]}, CV Score (MSE): {current_score:.4f}\")\n",
    "        \n",
    "        # Update the best subset if the current score is better than the best so far\n",
    "        if current_score < best_score:\n",
    "            best_score = current_score\n",
    "            best_feature_set = selected_features.copy()\n",
    "        \n",
    "        # Check if the maximum number of features has been reached\n",
    "        if max_features is not None and len(selected_features) >= max_features:\n",
    "            break\n",
    "\n",
    "    return (\n",
    "        selected_features,      # List of features in the order they were selected (this will be ALL features if max_features == None\n",
    "        best_scores,            # List of cross-validation scores corresponding to each addition in the previous list\n",
    "        best_feature_set,       # The subset of features that achieved the best CV score.\n",
    "        best_score              # The best CV score\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8dca9413-91ff-46c1-9a95-a284bdc4f005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features: ['Overall Qual'], CV Score (MSE): 2190446626.8455\n",
      "Features: ['Overall Qual', 'Gr Liv Area'], CV Score (MSE): 1634711678.9460\n",
      "Features: ['Overall Qual', 'Gr Liv Area', 'BsmtFin SF 1'], CV Score (MSE): 1431514773.2791\n",
      "Features: ['Overall Qual', 'Gr Liv Area', 'BsmtFin SF 1', 'Exter Qual'], CV Score (MSE): 1303120842.4610\n",
      "Features: ['Overall Qual', 'Gr Liv Area', 'BsmtFin SF 1', 'Exter Qual', 'Garage Cars'], CV Score (MSE): 1215929938.6529\n",
      "Features: ['Overall Qual', 'Gr Liv Area', 'BsmtFin SF 1', 'Exter Qual', 'Garage Cars', 'MS SubClass'], CV Score (MSE): 1151052377.3098\n",
      "Features: ['Overall Qual', 'Gr Liv Area', 'BsmtFin SF 1', 'Exter Qual', 'Garage Cars', 'MS SubClass', 'Bsmt Exposure'], CV Score (MSE): 1108574238.0102\n",
      "Features: ['Overall Qual', 'Gr Liv Area', 'BsmtFin SF 1', 'Exter Qual', 'Garage Cars', 'MS SubClass', 'Bsmt Exposure', 'Kitchen Qual'], CV Score (MSE): 1078501553.0717\n",
      "Features: ['Overall Qual', 'Gr Liv Area', 'BsmtFin SF 1', 'Exter Qual', 'Garage Cars', 'MS SubClass', 'Bsmt Exposure', 'Kitchen Qual', 'Year Built'], CV Score (MSE): 1054219329.0671\n",
      "Features: ['Overall Qual', 'Gr Liv Area', 'BsmtFin SF 1', 'Exter Qual', 'Garage Cars', 'MS SubClass', 'Bsmt Exposure', 'Kitchen Qual', 'Year Built', 'Overall Cond'], CV Score (MSE): 1033644755.3542\n",
      "Features: ['Overall Qual', 'Gr Liv Area', 'BsmtFin SF 1', 'Exter Qual', 'Garage Cars', 'MS SubClass', 'Bsmt Exposure', 'Kitchen Qual', 'Year Built', 'Overall Cond', 'Screen Porch'], CV Score (MSE): 1017025814.7002\n",
      "Features: ['Overall Qual', 'Gr Liv Area', 'BsmtFin SF 1', 'Exter Qual', 'Garage Cars', 'MS SubClass', 'Bsmt Exposure', 'Kitchen Qual', 'Year Built', 'Overall Cond', 'Screen Porch', 'Lot Area'], CV Score (MSE): 1002076717.7966\n",
      "Features: ['Overall Qual', 'Gr Liv Area', 'BsmtFin SF 1', 'Exter Qual', 'Garage Cars', 'MS SubClass', 'Bsmt Exposure', 'Kitchen Qual', 'Year Built', 'Overall Cond', 'Screen Porch', 'Lot Area', 'Bsmt Qual'], CV Score (MSE): 987026659.1167\n",
      "Features: ['Overall Qual', 'Gr Liv Area', 'BsmtFin SF 1', 'Exter Qual', 'Garage Cars', 'MS SubClass', 'Bsmt Exposure', 'Kitchen Qual', 'Year Built', 'Overall Cond', 'Screen Porch', 'Lot Area', 'Bsmt Qual', 'Mas Vnr Area'], CV Score (MSE): 976758087.7708\n",
      "Features: ['Overall Qual', 'Gr Liv Area', 'BsmtFin SF 1', 'Exter Qual', 'Garage Cars', 'MS SubClass', 'Bsmt Exposure', 'Kitchen Qual', 'Year Built', 'Overall Cond', 'Screen Porch', 'Lot Area', 'Bsmt Qual', 'Mas Vnr Area', 'Bsmt Full Bath'], CV Score (MSE): 968964332.1822\n",
      "Features: ['Overall Qual', 'Gr Liv Area', 'BsmtFin SF 1', 'Exter Qual', 'Garage Cars', 'MS SubClass', 'Bsmt Exposure', 'Kitchen Qual', 'Year Built', 'Overall Cond', 'Screen Porch', 'Lot Area', 'Bsmt Qual', 'Mas Vnr Area', 'Bsmt Full Bath', 'Sale Condition'], CV Score (MSE): 961720188.5583\n",
      "Features: ['Overall Qual', 'Gr Liv Area', 'BsmtFin SF 1', 'Exter Qual', 'Garage Cars', 'MS SubClass', 'Bsmt Exposure', 'Kitchen Qual', 'Year Built', 'Overall Cond', 'Screen Porch', 'Lot Area', 'Bsmt Qual', 'Mas Vnr Area', 'Bsmt Full Bath', 'Sale Condition', 'Fireplaces'], CV Score (MSE): 955847331.9063\n",
      "Features: ['Overall Qual', 'Gr Liv Area', 'BsmtFin SF 1', 'Exter Qual', 'Garage Cars', 'MS SubClass', 'Bsmt Exposure', 'Kitchen Qual', 'Year Built', 'Overall Cond', 'Screen Porch', 'Lot Area', 'Bsmt Qual', 'Mas Vnr Area', 'Bsmt Full Bath', 'Sale Condition', 'Fireplaces', 'Functional'], CV Score (MSE): 949260823.2658\n",
      "Features: ['Overall Qual', 'Gr Liv Area', 'BsmtFin SF 1', 'Exter Qual', 'Garage Cars', 'MS SubClass', 'Bsmt Exposure', 'Kitchen Qual', 'Year Built', 'Overall Cond', 'Screen Porch', 'Lot Area', 'Bsmt Qual', 'Mas Vnr Area', 'Bsmt Full Bath', 'Sale Condition', 'Fireplaces', 'Functional', 'Yr Sold'], CV Score (MSE): 944858744.7424\n",
      "Features: ['Overall Qual', 'Gr Liv Area', 'BsmtFin SF 1', 'Exter Qual', 'Garage Cars', 'MS SubClass', 'Bsmt Exposure', 'Kitchen Qual', 'Year Built', 'Overall Cond', 'Screen Porch', 'Lot Area', 'Bsmt Qual', 'Mas Vnr Area', 'Bsmt Full Bath', 'Sale Condition', 'Fireplaces', 'Functional', 'Yr Sold', 'Neighborhood'], CV Score (MSE): 940966102.0861\n",
      "Features: ['Overall Qual', 'Gr Liv Area', 'BsmtFin SF 1', 'Exter Qual', 'Garage Cars', 'MS SubClass', 'Bsmt Exposure', 'Kitchen Qual', 'Year Built', 'Overall Cond', 'Screen Porch', 'Lot Area', 'Bsmt Qual', 'Mas Vnr Area', 'Bsmt Full Bath', 'Sale Condition', 'Fireplaces', 'Functional', 'Yr Sold', 'Neighborhood', 'Wood Deck SF'], CV Score (MSE): 937689092.7501\n",
      "Features: ['Overall Qual', 'Gr Liv Area', 'BsmtFin SF 1', 'Exter Qual', 'Garage Cars', 'MS SubClass', 'Bsmt Exposure', 'Kitchen Qual', 'Year Built', 'Overall Cond', 'Screen Porch', 'Lot Area', 'Bsmt Qual', 'Mas Vnr Area', 'Bsmt Full Bath', 'Sale Condition', 'Fireplaces', 'Functional', 'Yr Sold', 'Neighborhood', 'Wood Deck SF', 'House Style'], CV Score (MSE): 934532366.2484\n",
      "Features: ['Overall Qual', 'Gr Liv Area', 'BsmtFin SF 1', 'Exter Qual', 'Garage Cars', 'MS SubClass', 'Bsmt Exposure', 'Kitchen Qual', 'Year Built', 'Overall Cond', 'Screen Porch', 'Lot Area', 'Bsmt Qual', 'Mas Vnr Area', 'Bsmt Full Bath', 'Sale Condition', 'Fireplaces', 'Functional', 'Yr Sold', 'Neighborhood', 'Wood Deck SF', 'House Style', 'Kitchen AbvGr'], CV Score (MSE): 931850299.5812\n",
      "Features: ['Overall Qual', 'Gr Liv Area', 'BsmtFin SF 1', 'Exter Qual', 'Garage Cars', 'MS SubClass', 'Bsmt Exposure', 'Kitchen Qual', 'Year Built', 'Overall Cond', 'Screen Porch', 'Lot Area', 'Bsmt Qual', 'Mas Vnr Area', 'Bsmt Full Bath', 'Sale Condition', 'Fireplaces', 'Functional', 'Yr Sold', 'Neighborhood', 'Wood Deck SF', 'House Style', 'Kitchen AbvGr', 'Street'], CV Score (MSE): 929115070.9878\n",
      "Features: ['Overall Qual', 'Gr Liv Area', 'BsmtFin SF 1', 'Exter Qual', 'Garage Cars', 'MS SubClass', 'Bsmt Exposure', 'Kitchen Qual', 'Year Built', 'Overall Cond', 'Screen Porch', 'Lot Area', 'Bsmt Qual', 'Mas Vnr Area', 'Bsmt Full Bath', 'Sale Condition', 'Fireplaces', 'Functional', 'Yr Sold', 'Neighborhood', 'Wood Deck SF', 'House Style', 'Kitchen AbvGr', 'Street', 'Roof Style'], CV Score (MSE): 927556522.5182\n",
      "Features: ['Overall Qual', 'Gr Liv Area', 'BsmtFin SF 1', 'Exter Qual', 'Garage Cars', 'MS SubClass', 'Bsmt Exposure', 'Kitchen Qual', 'Year Built', 'Overall Cond', 'Screen Porch', 'Lot Area', 'Bsmt Qual', 'Mas Vnr Area', 'Bsmt Full Bath', 'Sale Condition', 'Fireplaces', 'Functional', 'Yr Sold', 'Neighborhood', 'Wood Deck SF', 'House Style', 'Kitchen AbvGr', 'Street', 'Roof Style', 'Heating QC'], CV Score (MSE): 926370449.1919\n",
      "Features: ['Overall Qual', 'Gr Liv Area', 'BsmtFin SF 1', 'Exter Qual', 'Garage Cars', 'MS SubClass', 'Bsmt Exposure', 'Kitchen Qual', 'Year Built', 'Overall Cond', 'Screen Porch', 'Lot Area', 'Bsmt Qual', 'Mas Vnr Area', 'Bsmt Full Bath', 'Sale Condition', 'Fireplaces', 'Functional', 'Yr Sold', 'Neighborhood', 'Wood Deck SF', 'House Style', 'Kitchen AbvGr', 'Street', 'Roof Style', 'Heating QC', 'Exterior 1st'], CV Score (MSE): 924347760.5579\n",
      "Features: ['Overall Qual', 'Gr Liv Area', 'BsmtFin SF 1', 'Exter Qual', 'Garage Cars', 'MS SubClass', 'Bsmt Exposure', 'Kitchen Qual', 'Year Built', 'Overall Cond', 'Screen Porch', 'Lot Area', 'Bsmt Qual', 'Mas Vnr Area', 'Bsmt Full Bath', 'Sale Condition', 'Fireplaces', 'Functional', 'Yr Sold', 'Neighborhood', 'Wood Deck SF', 'House Style', 'Kitchen AbvGr', 'Street', 'Roof Style', 'Heating QC', 'Exterior 1st', 'Garage Cond'], CV Score (MSE): 923681684.8344\n",
      "Features: ['Overall Qual', 'Gr Liv Area', 'BsmtFin SF 1', 'Exter Qual', 'Garage Cars', 'MS SubClass', 'Bsmt Exposure', 'Kitchen Qual', 'Year Built', 'Overall Cond', 'Screen Porch', 'Lot Area', 'Bsmt Qual', 'Mas Vnr Area', 'Bsmt Full Bath', 'Sale Condition', 'Fireplaces', 'Functional', 'Yr Sold', 'Neighborhood', 'Wood Deck SF', 'House Style', 'Kitchen AbvGr', 'Street', 'Roof Style', 'Heating QC', 'Exterior 1st', 'Garage Cond', 'Bldg Type'], CV Score (MSE): 923019189.2154\n",
      "Features: ['Overall Qual', 'Gr Liv Area', 'BsmtFin SF 1', 'Exter Qual', 'Garage Cars', 'MS SubClass', 'Bsmt Exposure', 'Kitchen Qual', 'Year Built', 'Overall Cond', 'Screen Porch', 'Lot Area', 'Bsmt Qual', 'Mas Vnr Area', 'Bsmt Full Bath', 'Sale Condition', 'Fireplaces', 'Functional', 'Yr Sold', 'Neighborhood', 'Wood Deck SF', 'House Style', 'Kitchen AbvGr', 'Street', 'Roof Style', 'Heating QC', 'Exterior 1st', 'Garage Cond', 'Bldg Type', 'Land Slope'], CV Score (MSE): 922306229.7294\n",
      "Features: ['Overall Qual', 'Gr Liv Area', 'BsmtFin SF 1', 'Exter Qual', 'Garage Cars', 'MS SubClass', 'Bsmt Exposure', 'Kitchen Qual', 'Year Built', 'Overall Cond', 'Screen Porch', 'Lot Area', 'Bsmt Qual', 'Mas Vnr Area', 'Bsmt Full Bath', 'Sale Condition', 'Fireplaces', 'Functional', 'Yr Sold', 'Neighborhood', 'Wood Deck SF', 'House Style', 'Kitchen AbvGr', 'Street', 'Roof Style', 'Heating QC', 'Exterior 1st', 'Garage Cond', 'Bldg Type', 'Land Slope', 'Land Contour'], CV Score (MSE): 921465231.3533\n",
      "Features: ['Overall Qual', 'Gr Liv Area', 'BsmtFin SF 1', 'Exter Qual', 'Garage Cars', 'MS SubClass', 'Bsmt Exposure', 'Kitchen Qual', 'Year Built', 'Overall Cond', 'Screen Porch', 'Lot Area', 'Bsmt Qual', 'Mas Vnr Area', 'Bsmt Full Bath', 'Sale Condition', 'Fireplaces', 'Functional', 'Yr Sold', 'Neighborhood', 'Wood Deck SF', 'House Style', 'Kitchen AbvGr', 'Street', 'Roof Style', 'Heating QC', 'Exterior 1st', 'Garage Cond', 'Bldg Type', 'Land Slope', 'Land Contour', 'Enclosed Porch'], CV Score (MSE): 921067026.1650\n",
      "Features: ['Overall Qual', 'Gr Liv Area', 'BsmtFin SF 1', 'Exter Qual', 'Garage Cars', 'MS SubClass', 'Bsmt Exposure', 'Kitchen Qual', 'Year Built', 'Overall Cond', 'Screen Porch', 'Lot Area', 'Bsmt Qual', 'Mas Vnr Area', 'Bsmt Full Bath', 'Sale Condition', 'Fireplaces', 'Functional', 'Yr Sold', 'Neighborhood', 'Wood Deck SF', 'House Style', 'Kitchen AbvGr', 'Street', 'Roof Style', 'Heating QC', 'Exterior 1st', 'Garage Cond', 'Bldg Type', 'Land Slope', 'Land Contour', 'Enclosed Porch', 'Low Qual Fin SF'], CV Score (MSE): 920679988.5525\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Your code here:  Run Forward Feature Selection, plot the results, and print out the Best Feature Set and the Best CV Score found. \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m selected_features, best_scores, best_feature_set, best_score = \u001b[43mforward_feature_selection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmodel\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mneg_mean_squared_error\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtol\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1e-4\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_features\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m      5\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mBest Feature Set:\u001b[39m\u001b[33m\"\u001b[39m, best_feature_set)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest CV Score:\u001b[39m\u001b[33m\"\u001b[39m, best_score)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 28\u001b[39m, in \u001b[36mforward_feature_selection\u001b[39m\u001b[34m(X, y, model, scoring, cv, tol, max_features, n_jobs, verbose)\u001b[39m\n\u001b[32m     26\u001b[39m     current_features = selected_features + [feature]\n\u001b[32m     27\u001b[39m     \u001b[38;5;66;03m# Compute the CV score\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m     cv_score = -\u001b[43mcross_val_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcurrent_features\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     29\u001b[39m \u001b[43m                                \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     30\u001b[39m \u001b[43m                               \u001b[49m\u001b[43m)\u001b[49m.mean()\n\u001b[32m     31\u001b[39m     scores[feature] = cv_score\n\u001b[32m     32\u001b[39m \u001b[38;5;66;03m# Select the feature that minimizes the CV score\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:684\u001b[39m, in \u001b[36mcross_val_score\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, error_score)\u001b[39m\n\u001b[32m    681\u001b[39m \u001b[38;5;66;03m# To ensure multimetric format is not supported\u001b[39;00m\n\u001b[32m    682\u001b[39m scorer = check_scoring(estimator, scoring=scoring)\n\u001b[32m--> \u001b[39m\u001b[32m684\u001b[39m cv_results = \u001b[43mcross_validate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    685\u001b[39m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    686\u001b[39m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m=\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    687\u001b[39m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[43m=\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    688\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    689\u001b[39m \u001b[43m    \u001b[49m\u001b[43mscoring\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mscore\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    690\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcv\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    691\u001b[39m \u001b[43m    \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    692\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    693\u001b[39m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    694\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpre_dispatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    695\u001b[39m \u001b[43m    \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    696\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    697\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m cv_results[\u001b[33m\"\u001b[39m\u001b[33mtest_score\u001b[39m\u001b[33m\"\u001b[39m]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/model_selection/_validation.py:411\u001b[39m, in \u001b[36mcross_validate\u001b[39m\u001b[34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, params, pre_dispatch, return_train_score, return_estimator, return_indices, error_score)\u001b[39m\n\u001b[32m    408\u001b[39m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[32m    409\u001b[39m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[32m    410\u001b[39m parallel = Parallel(n_jobs=n_jobs, verbose=verbose, pre_dispatch=pre_dispatch)\n\u001b[32m--> \u001b[39m\u001b[32m411\u001b[39m results = \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    412\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    413\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    414\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    415\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    416\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mscorers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    417\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    418\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    419\u001b[39m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    420\u001b[39m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscore_params\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrouted_params\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    423\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_train_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_times\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m        \u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreturn_estimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m=\u001b[49m\u001b[43merror_score\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    431\u001b[39m _warn_or_raise_about_fit_failures(results, error_score)\n\u001b[32m    433\u001b[39m \u001b[38;5;66;03m# For callable scoring, the return type is only know after calling. If the\u001b[39;00m\n\u001b[32m    434\u001b[39m \u001b[38;5;66;03m# return type is a dictionary, the error scores can now be inserted with\u001b[39;00m\n\u001b[32m    435\u001b[39m \u001b[38;5;66;03m# the correct key.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/sklearn/utils/parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2001\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2002\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2003\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2004\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2005\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2007\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1647\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1649\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1650\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1653\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1654\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1655\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1656\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs) == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1760\u001b[39m     (\u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(\n\u001b[32m   1761\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING)):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1763\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1765\u001b[39m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[32m   1766\u001b[39m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[32m   1767\u001b[39m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Your code here:  Run Forward Feature Selection, plot the results, and print out the Best Feature Set and the Best CV Score found. \n",
    "\n",
    "selected_features, best_scores, best_feature_set, best_score = forward_feature_selection(\n",
    "    X_train, y_train, \"model\", scoring='neg_mean_squared_error', cv=5, tol=1e-4, max_features=None, verbose=True\n",
    ")\n",
    "\n",
    "print(\"\\nBest Feature Set:\", best_feature_set)\n",
    "print(\"Best CV Score:\", best_score)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9572c997-88f7-4373-9e84-8da9350da209",
   "metadata": {},
   "source": [
    "### Problem One Graded Questions\n",
    "\n",
    "Assign `a1a` to the number of features in the best feature set found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4fecff6-613e-4950-b65c-ddbd4d4006d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here; use an expression, not a constant derived by examining the data\n",
    "\n",
    "a1a = 0                     # replace 0 with an expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9d01a9f-72b0-46b1-8d76-9fac767cb793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1a = 0\n"
     ]
    }
   ],
   "source": [
    "# Do not change this cell in any way\n",
    "\n",
    "print(f\"a1a = {a1a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f794640-c8fd-4e72-92f3-46d53f63e82f",
   "metadata": {},
   "source": [
    "Assign `a1b` to the best CV RMSE score found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "56c91bdb-203f-48b5-bb70-7b755863f362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here; use an expression, not a constant derived by examining the data\n",
    "\n",
    "a1b = 0                     # replace 0 with an expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4414dc04-9447-4fa1-8f9a-69bef939964f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a1b = $0.00\n"
     ]
    }
   ],
   "source": [
    "# Do not change this cell in any way\n",
    "\n",
    "print(f\"a1b = ${a1b:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdb9d5e-a422-4295-94a6-ba9db542ecec",
   "metadata": {},
   "source": [
    "## **Problem Two: Backward Selection with the Ames Dataset**\n",
    "\n",
    "Now, repeat the same process as in Problem One, but using the `backward_feature_selection` algorithm from this week’s video notebook. Again, we will use 5-Fold CV scoring. \n",
    "\n",
    "**Steps to Follow:**\n",
    "1. **Observe** that we have provided the `backward_feature_selection` algorithm from this week's video notebook for you to use.\n",
    "2. **Run** the backward selection algorithm on the Ames dataset (`X_train` and `y_train`).\n",
    "3. **Plot** the results: Display the Root Mean Squared Error (RMSE) vs. the features removed by the algorithm.\n",
    "4. **Print** the Best Feature Set found by backward selection and the corresponding best CV RMSE Score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "413a71be-f510-43fa-8821-4715f3126e44",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "# Backward Feature Selection\n",
    "\n",
    "def backward_feature_selection(X, y, model, \n",
    "                               scoring='neg_mean_squared_error', \n",
    "                               cv = 5, \n",
    "                               tol=None,               # None = no delta cutoff\n",
    "                                                       # use 0.0 for \"no further improvements\"\n",
    "                                                       # and 1e-4 for \"point of diminishing returns\"                                      \n",
    "                               max_features=None,      # If None, remove features until only 1 remains\n",
    "                                                       # Otherwise, stop when this many features remain\n",
    "                               n_jobs=-1,\n",
    "                               verbose=True\n",
    "                              ):\n",
    "    \n",
    "    # Helper function to compute CV score using LinearRegression\n",
    "    def cv_score(features):\n",
    "        return -cross_val_score(model, X[features], y, \n",
    "                                scoring=scoring, cv=cv, \n",
    "                                n_jobs=n_jobs          ).mean()\n",
    "    \n",
    "    # Start with all features (using a list for easier manipulation)\n",
    "    features_remaining = list(X.columns)\n",
    "    \n",
    "    # Compute initial CV score with the full feature set\n",
    "    initial_score = cv_score(features_remaining)\n",
    "    \n",
    "    # Initialize tracking variables\n",
    "    best_score        = initial_score                # Best (lowest) CV score observed so far\n",
    "    best_feature_set  = features_remaining.copy()    # Feature set corresponding to best_score\n",
    "    selected_features = ['NONE']                     # List to record the order in which features are removed\n",
    "    best_scores       = [initial_score]              # List to record the CV score after each removal (starting with full set)\n",
    "    \n",
    "    if verbose:\n",
    "        print(\"Start with full set of features:\")\n",
    "        print(f'{features_remaining}  CV score (MSE): {np.around(initial_score, 4)}\\n')\n",
    "    \n",
    "    # Determine the target number of features to keep:\n",
    "    # For backward elimination, if max_features is None, we remove until 1 feature remains.\n",
    "    target_feature_count = 1 if max_features is None else max_features\n",
    "    \n",
    "    prev_score = initial_score\n",
    "    round_num = 1\n",
    "    # Continue removing features until we reach the target count\n",
    "    while len(features_remaining) > target_feature_count:\n",
    "        if verbose:\n",
    "            print(f'Round {round_num}:')\n",
    "            \n",
    "        # Initialize variables to track the best removal in this round\n",
    "        lowest_score = float('inf')\n",
    "        feature_to_remove = None\n",
    "        best_new_features = None\n",
    "        \n",
    "        # Try removing each feature one at a time\n",
    "        for feature in features_remaining:\n",
    "            new_feature_set = features_remaining.copy()\n",
    "            new_feature_set.remove(feature)\n",
    "            new_score = cv_score(new_feature_set)\n",
    "            if verbose:\n",
    "                print('Trying removal of:',feature, np.around(new_score, 4))\n",
    "            if new_score < lowest_score:\n",
    "                lowest_score = new_score\n",
    "                feature_to_remove = feature\n",
    "                best_new_features = new_feature_set\n",
    "        \n",
    "        # Check if improvement is significant enough (if tol is set)\n",
    "        if tol is not None and (prev_score - lowest_score) < tol:\n",
    "            if verbose:\n",
    "                print(\"\\nStopping early due to minimal improvement.\")\n",
    "            break\n",
    "        \n",
    "        # Update the best score and feature set if current removal improves performance\n",
    "        if lowest_score < best_score:\n",
    "            best_score = lowest_score\n",
    "            best_feature_set = best_new_features.copy()\n",
    "        \n",
    "        # Update trackers for this round\n",
    "        prev_score = lowest_score\n",
    "        features_remaining = best_new_features\n",
    "        selected_features.append(feature_to_remove)\n",
    "        best_scores.append(lowest_score)\n",
    "        \n",
    "        if verbose:\n",
    "            print(f'\\nRemoving {feature_to_remove}:  CV score (MSE) {np.around(lowest_score, 4)}\\n')\n",
    "        round_num += 1\n",
    "\n",
    "    return (\n",
    "        selected_features,      # Order in which features were removed\n",
    "        best_scores,            # CV scores after each removal step\n",
    "        best_feature_set,       # Feature set that achieved the best CV score\n",
    "        best_score              # Best (lowest) CV score\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c6af2391-6f2a-4255-9eca-82e98fc3211e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here:  Run Backward Feature Selection, plot the results, and print out the Best Feature Set and the Best CV RMSE Score found. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98687287-29bd-41f2-9323-f90d7ea3a49a",
   "metadata": {},
   "source": [
    "### Problem Two Graded Questions\n",
    "\n",
    "Assign `a2a` to the number of features in the best feature set found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81158187-be32-4a27-ad62-107f9550210b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here; use an expression, not a constant derived by examining the data\n",
    "\n",
    "a2a = 0                     # replace 0 with an expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "988d0fb1-6837-470e-b835-859a09a763f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2a = 0\n"
     ]
    }
   ],
   "source": [
    "# Do not change this cell in any way\n",
    "\n",
    "print(f\"a2a = {a2a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00238e72-993a-4a96-9cf9-c9eb756dbcc6",
   "metadata": {},
   "source": [
    "Assign `a2b` to the best CV RMSE score found."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "256564af-ee5b-466f-946d-c8507c8cba79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here; use an expression, not a constant derived by examining the data\n",
    "\n",
    "a2b = 0                     # replace 0 with an expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b05cff78-19ec-4ddd-bbc6-379e500a468a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a2b = $0.00\n"
     ]
    }
   ],
   "source": [
    "# Do not change this cell in any way\n",
    "\n",
    "print(f\"a2b = ${a2b:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d75e62d6-b553-4dc8-bb7b-5439a260c5ce",
   "metadata": {},
   "source": [
    "## **Problem Three: Ridge Regression on the Ames Housing Dataset**\n",
    "\n",
    "In this problem, we will apply Ridge Regression to the Ames Housing dataset. Ridge Regression includes a hyperparameter $\\alpha$ that controls the strength of the regularization penalty, which helps prevent overfitting by constraining the growth of the model’s coefficients. A higher $\\alpha$ penalizes large coefficients more, while a lower $\\alpha$ allows them to grow larger.\n",
    "\n",
    "When creating the model, the parameter must be specified, for example:\n",
    "\n",
    "```python\n",
    "ridge_model = Ridge(alpha=100)\n",
    "```\n",
    "\n",
    "This introduces another instance of the model selection problem: we must determine the value of $\\alpha$ that yields the best CV RMSE score.\n",
    "\n",
    "**Steps to Follow:**\n",
    "\n",
    "1. **Standardize the Data:**  \n",
    "   Ridge regression is sensitive to the scale of the features, so we will use `StandardScaler` to standardize the feature set to have a mean of 0 and a standard deviation of 1 before training and testing. Note that the target variable does **not** need to be scaled.\n",
    "\n",
    "2. **Perform Cross-Validation Over a Range of Alpha Values:**  \n",
    "   For each $\\alpha \\in \\{100, 110, 120, \\dots, 500\\}$, calculate the cross-validation RMSE score for the model using 5-Fold CV scoring.  \n",
    "\n",
    "3. **Visualize the Results:**  \n",
    "   Plot the CV RMSE scores against the $\\alpha$ values.\n",
    "\n",
    "4. **Identify the Best Alpha:**  \n",
    "   Determine the $\\alpha$ that results in the minimum CV RMSE Score and print it out, along with the score.\n",
    "\n",
    "**Tip:** It would be an *excellent* idea to add the suffix `_scaled` to any set to which you apply scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bdd7829-c8b5-4911-a739-e5e61b227b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb07668d-47c4-4928-bf7f-cf4ff0d6804f",
   "metadata": {},
   "source": [
    "### Problem Three Graded Answers\n",
    "\n",
    "Set `a3a` to the alpha determined to have the minimum CV RMSE score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a77a0908-06f0-414e-953f-19a541c1b8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here; use an expression, not a constant derived by examining the data\n",
    "\n",
    "a3a = 0                     # replace 0 with an expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3a1af1c-3812-4bef-bb96-a2a258bc6999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a3a = 0\n"
     ]
    }
   ],
   "source": [
    "# Do not change this cell in any way. \n",
    "\n",
    "print(f\"a3a = {a3a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f57e021-0e48-4d63-9c5e-f0d0b65078d4",
   "metadata": {},
   "source": [
    "Set `a3b` to the CV score found at that alpha. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5cacf50-2f40-4c1f-ab57-54cbc8f39fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here; use an expression, not a constant derived by examining the data\n",
    "\n",
    "a3b = 0                     # replace 0 with an expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26c1e982-1e88-40fb-a896-6206b79fdd15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a3b = $0.00\n"
     ]
    }
   ],
   "source": [
    "# Do not change this cell in any way. \n",
    "\n",
    "print(f\"a3b = ${a3b:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb57239-029f-4f53-8d8f-7ad5006a7b7e",
   "metadata": {},
   "source": [
    "## **Problem Four: Evaluate Your Best Model**\n",
    "\n",
    "In this final problem, you will identify the model with the best cross-validation RMSE score and evaluate its performance on the held-out test set.\n",
    "\n",
    "#### **Steps to Follow:**\n",
    "\n",
    "1. **Identify the Best Model:**\n",
    "   From your previous results, select the model that achieved the lowest CV RMSE score. \n",
    "\n",
    "3. **Train and Test the Selected Model:** \n",
    "   - For Forward or Backward Feature Selection:  Train a Linear Regression model using `X_train` **restricted to the selected best feature set**, and evaluate it on `X_test` restricted to the same feature set.\n",
    "   - For Ridge Regression:   Train a Ridge Regression model using the best alpha found from cross-validation, with `StandardScaler` applied to both `X_train` and `X_test` before training and testing.\n",
    "\n",
    "4. **Report Your Results:**\n",
    "   Print the name of the best model and the test RMSE in dollars.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bea61bba-4433-4928-9a5b-8dd281ca1ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f254631-5f4d-4b2a-b495-8c9865369f1c",
   "metadata": {},
   "source": [
    "### Problem Four Graded Answers\n",
    "\n",
    "Set `a4a` to the best model, according to the CV RMSE score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "60e8b581-3764-4c02-b3ac-1a883e16d1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here\n",
    "\n",
    "a4a = 0                     # replace 0 with one of [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "395043f6-84ad-4d07-a029-160b29537131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a4a = 0\n"
     ]
    }
   ],
   "source": [
    "# Do not change this cell in any way. \n",
    "\n",
    "print(f\"a4a = {a4a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68877104-7f7a-41c1-89c8-173288d268e0",
   "metadata": {},
   "source": [
    "Set `a4b` to the test RMSE for the best model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "afe97ea9-9370-49aa-a99a-f08cfa433376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here; use an expression, not a constant derived by examining the data\n",
    "\n",
    "a4b = 0                     # replace 0 with an expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "371f2f02-b7d3-462e-9ed7-90a0c98c87d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a4b = $0.00\n"
     ]
    }
   ],
   "source": [
    "# Do not change this cell in any way. \n",
    "\n",
    "print(f\"a4b = ${a4b:,.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2e8a08b-fdaa-4aaf-9448-a2064374ee3e",
   "metadata": {},
   "source": [
    "### Final question...\n",
    "\n",
    "Why didn't we evaluate *all* the models on the test set and compare them?\n",
    "\n",
    "### Some answers...\n",
    "\n",
    "It’s tempting to reconsider your choice based on test scores, but this violates the core principle of not \"training to the test.\" That’s why we deliberately avoided evaluating all models on the test set.\n",
    "\n",
    "The test set doesn’t influence model training; it serves as a final, unbiased check on how well your chosen model generalizes to unseen data, ensuring that your selection process wasn’t overly optimistic.\n",
    "\n",
    "A natural **next question** is: Why use a test set at all? Beyond being an industry-standard practice that simulates the real world—where you can’t adjust your model after deployment—consider:\n",
    "\n",
    "- **Validating your workflow:** A strong test score confirms that your model selection process (feature selection, hyperparameter tuning, etc.) was sound. A poor test score despite good cross-validation results may indicate overfitting or a flawed approach.\n",
    "  \n",
    "- **Guarding against over-optimism:** Cross-validation can be slightly optimistic, especially with limited data or repeated trials. The test set provides a final safeguard against relying on an overly tuned model.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
